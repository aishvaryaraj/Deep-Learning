{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6fb6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b55938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "training_data = datasets.MNIST(root=\"data\", train=True, download=True)\n",
    "test_data = datasets.MNIST(root=\"data\", train=False, download=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ee715f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs before transformation: (28, 28)\n"
     ]
    }
   ],
   "source": [
    "sample_image, sample_label = training_data[0]\n",
    "print(\"Inputs before transformation:\", sample_image.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28a3103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, (image, label) in enumerate(training_data):\n",
    "    if i >= 9:  # Only plot the first 9 images\n",
    "        break\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e26c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to tensor, normalising and flattening\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)),\n",
    "    transforms.Lambda(lambda x: torch.flatten(x))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c101bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f92708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed image size: torch.Size([784])\n"
     ]
    }
   ],
   "source": [
    "image_transformed, label_transformed = training_data[0]\n",
    "print(\"Transformed image size:\", image_transformed.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d8e363",
   "metadata": {},
   "source": [
    "## Preprocessing Explanation\n",
    "The data is coverted to tensors to make sure the input is numerical so that operations can be performed on it. The data is normalised to keep weights within a reasonable scale by keeping inputs values within a range such that the mean and standard deviation are 0.5, centering the data around zero. The data is flattened to be of the correct format for the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67cc8a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(training_data, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b738b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation = F.relu \n",
    "        \n",
    "        self.fc1 = nn.Linear(28 * 28, 200)  # input size = 784 (flattened image) \n",
    "        self.fc2 = nn.Linear(200, 100) #hidden layer\n",
    "        self.fc3 = nn.Linear(100, 10) #output layer with 10 classes (0-9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))  \n",
    "        x = self.activation(self.fc2(x))    \n",
    "        x = self.activation(self.fc3(x))    \n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34946dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer and loss function\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbaf944",
   "metadata": {},
   "source": [
    "## Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459536b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "train_loss_history = list()\n",
    "val_loss_history = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad() #zero out gradients\n",
    "\n",
    "        #pass through network and loss backpropagation \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1} training accuracy: {train_correct/len(train_loader):.2f}% training loss: {train_loss/len(train_loader):.5f}')\n",
    "    train_loss_history.append(train_loss/len(train_loader))\n",
    "\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    net.eval()\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        val_correct += (preds == labels).sum().item()\n",
    "        val_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1} validation accuracy: {val_correct/len(test_loader):.2f}% validation loss: {val_loss/len(test_loader):.5f}')\n",
    "    val_loss_history.append(val_loss/len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bebf536",
   "metadata": {},
   "source": [
    "## Tuning Hyperparameters\n",
    "\n",
    "* adding layers to the neural network\n",
    "* using leaky relu\n",
    "* using stochastic gradient descent with momentum instead of adam\n",
    "* changing number of epochs to 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # After three pooling layers, the size becomes 3x3 (from 28x28).\n",
    "        self.fc1 = nn.Linear(128*3*3, 500) \n",
    "        self.fc2 = nn.Linear(500, 400)\n",
    "        self.fc3 = nn.Linear(400, 200)\n",
    "        self.fc4 = nn.Linear(200, 100)\n",
    "        self.fc5 = nn.Linear(100, 10)\n",
    "        \n",
    "        # Activation\n",
    "        self.activation = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = self.pool(self.activation(self.conv1(x)))\n",
    "        x = self.pool(self.activation(self.conv2(x)))\n",
    "        x = self.pool(self.activation(self.conv3(x)))\n",
    "        \n",
    "        x = x.view(-1, 128*3*3)  # Flatten after three pooling layers\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.activation(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "new_net = NewNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cba76945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_FC_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_FC_Net, self).__init__()\n",
    "    \n",
    "        self.fc1 = nn.Linear(784, 512)# Input is 28*28 = 784 when flattened\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 10)  # 10 classes (0-9)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n",
    "    \n",
    "new_net = MNIST_FC_Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47caa0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(new_net.parameters(), lr=0.01, momentum=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83aa655e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 training accuracy: 3.83% training loss: 2.03678\n",
      "Epoch 1 validation accuracy: 3.24% validation loss: 2.09447\n",
      "Epoch 2 training accuracy: 2.13% training loss: 2.32121\n",
      "Epoch 2 validation accuracy: 2.58% validation loss: 2.27326\n",
      "Epoch 3 training accuracy: 1.95% training loss: 2.30835\n",
      "Epoch 3 validation accuracy: 3.32% validation loss: 2.19497\n",
      "Epoch 4 training accuracy: 1.74% training loss: 2.30031\n",
      "Epoch 4 validation accuracy: 1.53% validation loss: 2.30357\n",
      "Epoch 5 training accuracy: 1.72% training loss: 2.46152\n",
      "Epoch 5 validation accuracy: 1.56% validation loss: 2.30604\n",
      "Epoch 6 training accuracy: 1.69% training loss: 2.31068\n",
      "Epoch 6 validation accuracy: 1.82% validation loss: 2.30276\n",
      "Epoch 7 training accuracy: 1.71% training loss: 2.30387\n",
      "Epoch 7 validation accuracy: 1.82% validation loss: 2.30216\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0h/ntqkkvp97hn01l5khzs69svh0000gn/T/ipykernel_70476/3479495864.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mhas_sparse_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             sgd(params_with_grad,\n\u001b[0m\u001b[1;32m     77\u001b[0m                 \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36msgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, has_sparse_grad, foreach, weight_decay, momentum, lr, dampening, nesterov, maximize)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_sgd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    223\u001b[0m          \u001b[0md_p_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m          \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36m_single_tensor_sgd\u001b[0;34m(params, d_p_list, momentum_buffer_list, weight_decay, momentum, lr, dampening, nesterov, maximize, has_sparse_grad)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mmomentum_buffer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "train_loss_history = list()\n",
    "val_loss_history = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    new_net.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad() #zero out gradients\n",
    "\n",
    "        #pass through network and loss backpropagation \n",
    "        outputs = new_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1} training accuracy: {train_correct/len(train_loader):.2f}% training loss: {train_loss/len(train_loader):.5f}')\n",
    "    train_loss_history.append(train_loss/len(train_loader))\n",
    "\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    new_net.eval()\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = new_net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        val_correct += (preds == labels).sum().item()\n",
    "        val_loss += loss.item()\n",
    "    print(f'Epoch {epoch + 1} validation accuracy: {val_correct/len(test_loader):.2f}% validation loss: {val_loss/len(test_loader):.5f}')\n",
    "    val_loss_history.append(val_loss/len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cd1c1a",
   "metadata": {},
   "source": [
    "## Random Restarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f96cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "num_epochs = 15\n",
    "num_restarts = 5\n",
    "\n",
    "# Function to reset model weights\n",
    "def weight_reset(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        m.reset_parameters()\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model = None\n",
    "\n",
    "train_loss_history = list()\n",
    "val_loss_history = list()\n",
    "\n",
    "for restart in range(num_restarts):\n",
    "\n",
    "    # Reinitialize model's weights and optimizer\n",
    "    new_net.apply(weight_reset)\n",
    "    optimizer = optim.SGD(new_net.parameters(), lr=0.01)  # Assuming fixed learning rate\n",
    "\n",
    "    print(f\"Restart: {restart + 1}\")\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        new_net.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "\n",
    "            optimizer.zero_grad()  # zero out gradients\n",
    "\n",
    "            outputs = new_net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch + 1} training accuracy: {train_correct/len(train_loader.dataset):.2f}% training loss: {train_loss/len(train_loader):.5f}')\n",
    "        train_loss_history.append(train_loss/len(train_loader))\n",
    "\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        new_net.eval()\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = new_net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch {epoch + 1} validation accuracy: {val_correct/len(test_loader.dataset):.2f}% validation loss: {val_loss/len(test_loader):.5f}')\n",
    "        val_loss_history.append(val_loss/len(test_loader))\n",
    "    \n",
    "    # Store best model\n",
    "    if val_loss/len(test_loader) < best_val_loss:\n",
    "        best_val_loss = val_loss/len(test_loader)\n",
    "        best_model = copy.deepcopy(new_net)\n",
    "\n",
    "\n",
    "# Now, after all restarts are done, evaluate the best model on the test set:\n",
    "best_model.eval()  \n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "\n",
    "for inputs, labels in test_loader:\n",
    "    outputs = best_model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    test_correct += (preds == labels).sum().item()\n",
    "    test_loss += loss.item()\n",
    "\n",
    "print(f'Final test accuracy with best model: {test_correct/len(test_loader.dataset):.2f}% test loss: {test_loss/len(test_loader):.5f}')\n",
    "\n",
    "# If you wish to save the best model:\n",
    "torch.save(best_model.state_dict(), 'best_model.pth')\n",
    "\n",
    "# Later, if you wish to load this model:\n",
    "# model = SimpleModel()  # or whatever your model class name is\n",
    "# model.load_state_dict(torch.load('best_model.pth'))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e343f9ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce320e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
